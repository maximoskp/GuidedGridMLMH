{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b18473c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from data_utils import GuidedGridMLMDataset, GuidedGridMLM_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "from GridMLM_tokenizers import GuidedGridMLMTokenizer\n",
    "from models import GuidedMLMH\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from generate_utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ff1e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data file.\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/media/maindisk/data/hooktheory_hr/hooktheory_CA_train'\n",
    "\n",
    "tokenizer = GuidedGridMLMTokenizer(fixed_length=256)\n",
    "train_dataset = GuidedGridMLMDataset(train_dir, tokenizer, 512, frontloading=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a169ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = 'unf_CA'\n",
    "device_name = 'cuda:2'\n",
    "curriculum_type = 'random'\n",
    "ablation = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6706a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model( curriculum_type, subfolder, ablation, device_name, tokenizer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780de6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9105/9105 [00:50<00:00, 182.08it/s]\n"
     ]
    }
   ],
   "source": [
    "all_z_list = []\n",
    "for d in tqdm(train_dataset):\n",
    "    z, mu, logvar, recon_seq, z_proj = model.vae(torch.LongTensor([d['input_ids']]).to(model.device)) # TODO: do we need to detach?\n",
    "    z_dmodel = model.guidance_to_dmodel(z)\n",
    "    all_z_list.append( z_dmodel.tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9832114a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9105, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "all_z = torch.FloatTensor(all_z_list)\n",
    "print(all_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a885bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_film_modulation(film_layer, all_z, threshold=0.1):\n",
    "    with torch.no_grad():\n",
    "        # W_gamma = film_layer.film_gamma.weight      # (D_out, D_z)\n",
    "        # b_gamma = film_layer.film_gamma.bias        # (D_out)\n",
    "        # W_beta = film_layer.film_beta.weight\n",
    "        # b_beta = film_layer.film_beta.bias\n",
    "\n",
    "        # # Compute gamma(z) and beta(z)\n",
    "        # gamma_vals = (all_z @ W_gamma.T + b_gamma)  # (N, D_out)\n",
    "        # beta_vals = (all_z @ W_beta.T + b_beta)\n",
    "\n",
    "        gamma_vals = film_layer.film_gamma(all_z)\n",
    "        beta_vals = film_layer.film_beta(all_z)\n",
    "\n",
    "        # Metrics\n",
    "        gamma_diff_1 = torch.norm(gamma_vals - 1.0, dim=1)  # Distance from identity\n",
    "        gamma_diff_0 = torch.norm(gamma_vals, dim=1)  # Distance from cancelling\n",
    "        beta_norm = torch.norm(beta_vals, dim=1)\n",
    "\n",
    "        near_identity = ((gamma_diff_1 < threshold) & (beta_norm < threshold)).all(dim=1) | \\\n",
    "            ((gamma_diff_0 < threshold) & (beta_norm < threshold)).all(dim=1)\n",
    "        print('near_identity: ', near_identity.shape)\n",
    "        percent_near_identity = 100 * near_identity.sum().item() / all_z.size(0)\n",
    "\n",
    "        print(f\"Layer: {film_layer.__class__.__name__}\")\n",
    "        print(f\"γ values: min {gamma_vals.min():.3f}, max {gamma_vals.max():.3f}, mean {gamma_vals.mean():.3f}\")\n",
    "        print(f\"β values: min {beta_vals.min():.3f}, max {beta_vals.max():.3f}, mean {beta_vals.mean():.3f}\")\n",
    "        print(f\"Proportion near-identity FiLM: {percent_near_identity:.2f}%\")\n",
    "\n",
    "        return gamma_vals, beta_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b09f48d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Layer 0 ===\n",
      "gamma_vals:  torch.Size([9105, 1, 512])\n",
      "gamma_diff:  torch.Size([9105, 512])\n",
      "near_identity:  torch.Size([9105])\n",
      "Layer: FiLMTransformerEncoderLayer\n",
      "γ values: min -2.020, max 2.264, mean 0.030\n",
      "β values: min -1.213, max 1.250, mean -0.002\n",
      "Proportion near-identity FiLM: 0.00%\n",
      "\n",
      "=== Layer 1 ===\n",
      "gamma_vals:  torch.Size([9105, 1, 512])\n",
      "gamma_diff:  torch.Size([9105, 512])\n",
      "near_identity:  torch.Size([9105])\n",
      "Layer: FiLMTransformerEncoderLayer\n",
      "γ values: min -2.299, max 1.968, mean -0.006\n",
      "β values: min -1.186, max 1.350, mean 0.004\n",
      "Proportion near-identity FiLM: 0.00%\n",
      "\n",
      "=== Layer 2 ===\n",
      "gamma_vals:  torch.Size([9105, 1, 512])\n",
      "gamma_diff:  torch.Size([9105, 512])\n",
      "near_identity:  torch.Size([9105])\n",
      "Layer: FiLMTransformerEncoderLayer\n",
      "γ values: min -2.079, max 2.161, mean -0.025\n",
      "β values: min -1.413, max 1.268, mean 0.003\n",
      "Proportion near-identity FiLM: 0.00%\n",
      "\n",
      "=== Layer 3 ===\n",
      "gamma_vals:  torch.Size([9105, 1, 512])\n",
      "gamma_diff:  torch.Size([9105, 512])\n",
      "near_identity:  torch.Size([9105])\n",
      "Layer: FiLMTransformerEncoderLayer\n",
      "γ values: min -2.004, max 2.040, mean -0.007\n",
      "β values: min -1.175, max 1.237, mean -0.001\n",
      "Proportion near-identity FiLM: 0.00%\n",
      "\n",
      "=== Layer 4 ===\n",
      "gamma_vals:  torch.Size([9105, 1, 512])\n",
      "gamma_diff:  torch.Size([9105, 512])\n",
      "near_identity:  torch.Size([9105])\n",
      "Layer: FiLMTransformerEncoderLayer\n",
      "γ values: min -2.099, max 2.541, mean 0.009\n",
      "β values: min -1.266, max 1.213, mean -0.002\n",
      "Proportion near-identity FiLM: 0.00%\n",
      "\n",
      "=== Layer 5 ===\n",
      "gamma_vals:  torch.Size([9105, 1, 512])\n",
      "gamma_diff:  torch.Size([9105, 512])\n",
      "near_identity:  torch.Size([9105])\n",
      "Layer: FiLMTransformerEncoderLayer\n",
      "γ values: min -2.054, max 2.094, mean 0.004\n",
      "β values: min -1.299, max 1.266, mean 0.001\n",
      "Proportion near-identity FiLM: 0.00%\n",
      "\n",
      "=== Layer 6 ===\n",
      "gamma_vals:  torch.Size([9105, 1, 512])\n",
      "gamma_diff:  torch.Size([9105, 512])\n",
      "near_identity:  torch.Size([9105])\n",
      "Layer: FiLMTransformerEncoderLayer\n",
      "γ values: min -2.669, max 2.455, mean 0.002\n",
      "β values: min -1.346, max 1.342, mean -0.006\n",
      "Proportion near-identity FiLM: 0.00%\n",
      "\n",
      "=== Layer 7 ===\n",
      "gamma_vals:  torch.Size([9105, 1, 512])\n",
      "gamma_diff:  torch.Size([9105, 512])\n",
      "near_identity:  torch.Size([9105])\n",
      "Layer: FiLMTransformerEncoderLayer\n",
      "γ values: min -2.588, max 2.676, mean -0.001\n",
      "β values: min -1.872, max 2.459, mean -0.002\n",
      "Proportion near-identity FiLM: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# all_z = collect_z_vectors_from_training_data(model.vae, train_loader)\n",
    "\n",
    "for i, layer in enumerate(model.encoder.layers):\n",
    "    print(f\"\\n=== Layer {i} ===\")\n",
    "    analyze_film_modulation(layer, all_z.to(model.device))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
